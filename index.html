---
layout: default
title: Max Ent 2018
---

		<div class="blurb">
			<h1>Max Ent 2018 <img src="ENIGMA2.jpg" alt="Engigma", width="460", height="230", align="right", style="padding:10px;"></h1>
			<h4>38<sup>th</sup> International Workshop on Bayesian Inference and Maximum Entropy Methods in Science and Engineering</h4>
			<p><strong>02-06 July, 2018 – The Alan Turing Institute, British Library, London, UK</strong></p>
			
			
		</div> 

<div class="blurb">
	<p>For over 37 years, the Max Ent workshops have explored the use of Bayesian and Maximum Entropy methods in scientific and engineering applications. 
		The workshop invites contributions on all aspects of probabilistic inference, including novel techniques and applications, and work that sheds new light on the foundations of inference. 
		In previous workshops, areas of application have included astronomy and astrophysics, chemistry, communications theory, cosmology, climate studies, earth science, fluid mechanics, genetics, geophysics, machine learning, material science, medical imaging, nanoscience, source separation, thermodynamics (equilibrium and non-equilibrium), particle physics, plasma physics, quantum mechanics, robotics and social sciences. 
		Bayesian computational techniques such as Markov chain Monte Carlo sampling have been regular topics, as are approximate inferential methods. Foundational issues involving probability theory and information theory, and the novel application of inference to illuminate the foundations of physical theories, have also been of keen interest.</p>
	
	<p>
		The workshop will include a one-day tutorial session (Monday 2 July), invited papers, contributed papers and poster presentations. 
		Contributed papers related to the above topics are being solicited. 
		Especially encouraged are papers whose content is novel, either as to approach or area of application. 
		<!--One-page abstracts of the proposed papers should be submitted via this website. -->
		Selected papers will be edited by the organizing committee and published in the proceedings. 
		In addition, a special issue of the journal Entropy is planned that will be open to extended papers (invited and contributed) based on workshop contributions. 
		These papers will be subjected to the journal's usual peer-review process. 
	<p> 
</div>




<!--

---
layout: default
title: Stein
---

		<div class="blurb">
			<h1>Stein's Method at ICML 2019 <img src="ENIGMA2.jpg" alt="Engigma", width="460", height="280", align="right", style="padding:10px;"></h1>
			<h4>Stein's Method for Machine Learning in Statistics</h4>
			<p><strong>TBC, June, 2019 – International Conference on Machine Learning (ICML)</strong></p>
			
			
		</div> 

<div class="blurb">
	<p>Stein's method is a technique from probability theory for bounding the distance between probability measures using differential and difference operators. 
Although the method was initially designed as a technique for proving central limit theorems, it has recently caught the attention of the machine learning (ML) community and has been used for a variety of practical tasks. 
Recent applications include goodness-of-fit testing, generative modeling, global non-convex optimisation, variational inference, de novo sampling, constructing powerful control variates for Monte Carlo variance reduction, and measuring the quality of (approximate) Markov chain Monte Carlo algorithms.  </p>



<p>Although Stein's method has already had significant impact in ML, most of the applications only scratch the surface of this rich area of research in probability theory. 
There would be significant gains to be made by encouraging both communities to interact directly, and this inaugural workshop is an attempt to achieve that.</p>

</div>

-->


